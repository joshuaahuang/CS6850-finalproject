{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlU84aKQhGix",
        "outputId": "7a743d72-1bc0-4460-9db1-1e9e40f8774a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.5.0+cpu.html\n",
            "Requirement already satisfied: torch-cluster in /usr/local/lib/python3.10/dist-packages (1.6.3+pt25cpu)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-cluster) (1.13.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-cluster) (1.26.4)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (24.3.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (75.6.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (0.45.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Collecting torch-geometric\n",
            "  Using cached torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.11.10)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.8.30)\n",
            "Using cached torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.6.1\n"
          ]
        }
      ],
      "source": [
        "!pip install torch-cluster -f https://data.pyg.org/whl/torch-2.5.0+cpu.html\n",
        "!pip install --upgrade pip setuptools wheel\n",
        "!pip install --upgrade torch torch-geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHZ5Dca6hGiy",
        "outputId": "ff6dcf22-4d7e-44cb-b9cb-e8c51fe5c674"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "pip install certifi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "rNsLoXWBhGiz"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch_cluster\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.nn import Node2Vec, PNAConv\n",
        "from torch_geometric.transforms import NormalizeFeatures\n",
        "from torch_geometric.utils import degree\n",
        "\n",
        "# Set the device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TolHwDZJhGiz",
        "outputId": "7dab42a7-8818-4ea6-ceaf-64d79b25aaeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
            "Processing...\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "# Load the Cora dataset\n",
        "dataset = Planetoid(root='data/Cora', name='Cora', transform=NormalizeFeatures())\n",
        "data = dataset[0].to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "hRqTNKMZhGiz"
      },
      "outputs": [],
      "source": [
        "# Configure Node2Vec parameters\n",
        "embedding_dim = 64\n",
        "walk_length = 20\n",
        "context_size = 10\n",
        "walks_per_node = 10\n",
        "num_negative_samples = 1\n",
        "\n",
        "node2vec = Node2Vec(\n",
        "    data.edge_index,\n",
        "    embedding_dim=embedding_dim,\n",
        "    walk_length=walk_length,\n",
        "    context_size=context_size,\n",
        "    walks_per_node=walks_per_node,\n",
        "    num_negative_samples=num_negative_samples,\n",
        "    sparse=True\n",
        ").to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HLohvavhGi0",
        "outputId": "8b7bd878-ef2c-4436-ddc3-f55b96bbf3ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Node2Vec embeddings...\n",
            "Epoch: 10, Loss: 1.2228\n",
            "Epoch: 20, Loss: 0.9053\n",
            "Epoch: 30, Loss: 0.8589\n",
            "Epoch: 40, Loss: 0.8422\n",
            "Epoch: 50, Loss: 0.8359\n"
          ]
        }
      ],
      "source": [
        "# Train the Node2Vec embeddings\n",
        "loader = node2vec.loader(batch_size=128, shuffle=True)\n",
        "optimizer_n2v = torch.optim.SparseAdam(list(node2vec.parameters()), lr=0.01)\n",
        "\n",
        "def train_node2vec():\n",
        "    node2vec.train()\n",
        "    total_loss = 0\n",
        "    for pos_rw, neg_rw in loader:\n",
        "        optimizer_n2v.zero_grad()\n",
        "        loss = node2vec.loss(pos_rw.to(device), neg_rw.to(device))\n",
        "        loss.backward()\n",
        "        optimizer_n2v.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "print(\"Training Node2Vec embeddings...\")\n",
        "for epoch in range(1, 51):\n",
        "    loss = train_node2vec()\n",
        "    if epoch % 10 == 0:\n",
        "        print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "mi0EPKGbhGi0"
      },
      "outputs": [],
      "source": [
        "# Extract the learned Node2Vec embeddings\n",
        "node2vec.eval()\n",
        "node_embeddings = node2vec().detach()  # [num_nodes, embedding_dim]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "0JxhlAMjhGi0"
      },
      "outputs": [],
      "source": [
        "# Compute node degrees for PNAConv\n",
        "deg = degree(data.edge_index[0], data.num_nodes).to(device)\n",
        "\n",
        "# Define aggregators and scalers for PNAConv\n",
        "aggregators = ['mean', 'min', 'max', 'std']\n",
        "scalers = ['identity', 'amplification', 'attenuation']\n",
        "\n",
        "hidden_dim = 64"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PNAModelWithAttention(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, aggregators, scalers, deg, node_embeddings):\n",
        "        super(PNAModelWithAttention, self).__init__()\n",
        "        self.conv = PNAConv(in_channels, hidden_channels, aggregators=aggregators,\n",
        "                            scalers=scalers, deg=deg)\n",
        "        self.lin = nn.Linear(hidden_channels, out_channels)\n",
        "\n",
        "        self.attention_weights = nn.Parameter(torch.rand(node_embeddings.size(0), 1))\n",
        "        self.register_buffer('n2v_emb', node_embeddings)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        # PNA aggregation step\n",
        "        h = self.conv(x, edge_index)\n",
        "\n",
        "        # Compute attention weights\n",
        "        alpha = torch.sigmoid(self.attention_weights)  # Ensure values are between 0 and 1\n",
        "\n",
        "        # Apply attention-based fusion\n",
        "        h_fused = alpha * self.n2v_emb + (1 - alpha) * h\n",
        "        h_fused = F.relu(h_fused)\n",
        "        h_fused = self.lin(h_fused)\n",
        "        return h_fused\n",
        "\n",
        "model = PNAModelWithAttention(\n",
        "    in_channels=dataset.num_node_features,\n",
        "    hidden_channels=hidden_dim,\n",
        "    out_channels=dataset.num_classes,\n",
        "    aggregators=aggregators,\n",
        "    scalers=scalers,\n",
        "    deg=deg,\n",
        "    node_embeddings=node_embeddings\n",
        ").to(device)"
      ],
      "metadata": {
        "id": "HebTrhTGP7zm"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "rimbW_kJhGi1"
      },
      "outputs": [],
      "source": [
        "# Setup training components\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "x = data.x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "v9xgciY3hGi1"
      },
      "outputs": [],
      "source": [
        "def train():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    out = model(x, data.edge_index)\n",
        "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "@torch.no_grad()\n",
        "def test():\n",
        "    model.eval()\n",
        "    out = model(x, data.edge_index)\n",
        "    pred = out.argmax(dim=1)\n",
        "    accs = []\n",
        "    for mask in [data.train_mask, data.val_mask, data.test_mask]:\n",
        "        correct = pred[mask].eq(data.y[mask]).sum().item()\n",
        "        accs.append(correct / mask.sum().item())\n",
        "    return accs  # [train_acc, val_acc, test_acc]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okEFMTsfhGi1",
        "outputId": "4615e9ba-9643-45b2-8fe9-7c45d9b08fce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training PNA model with Node2Vec embeddings...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
            "  warnings.warn(message)\n",
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
            "  warnings.warn(message)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 020, Loss: 0.1074, Train: 1.0000, Val: 0.5360, Test: 0.5560\n",
            "Epoch: 040, Loss: 0.0074, Train: 1.0000, Val: 0.5900, Test: 0.6180\n",
            "Epoch: 060, Loss: 0.0058, Train: 1.0000, Val: 0.6280, Test: 0.6420\n",
            "Epoch: 080, Loss: 0.0046, Train: 1.0000, Val: 0.6440, Test: 0.6740\n",
            "Epoch: 100, Loss: 4.7131, Train: 0.3286, Val: 0.0620, Test: 0.0850\n",
            "Epoch: 120, Loss: 0.0045, Train: 1.0000, Val: 0.5420, Test: 0.5310\n",
            "Epoch: 140, Loss: 0.0003, Train: 1.0000, Val: 0.5420, Test: 0.5370\n",
            "Epoch: 160, Loss: 0.0004, Train: 1.0000, Val: 0.5400, Test: 0.5430\n",
            "Epoch: 180, Loss: 0.0007, Train: 1.0000, Val: 0.5500, Test: 0.5520\n",
            "Epoch: 200, Loss: 0.0010, Train: 1.0000, Val: 0.5700, Test: 0.5710\n",
            "\n",
            "Best Validation Accuracy: 0.6500\n",
            "Test Accuracy at Best Val: 0.6720\n"
          ]
        }
      ],
      "source": [
        "# Train and evaluate\n",
        "best_val_acc = 0\n",
        "test_acc_at_best_val = 0\n",
        "\n",
        "print(\"Training PNA model with Node2Vec embeddings...\")\n",
        "for epoch in range(1, 201):\n",
        "    loss = train()\n",
        "    train_acc, val_acc, test_acc = test()\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        test_acc_at_best_val = test_acc\n",
        "\n",
        "    if epoch % 20 == 0:\n",
        "        print(f\"Epoch: {epoch:03d}, Loss: {loss:.4f}, \"\n",
        "              f\"Train: {train_acc:.4f}, Val: {val_acc:.4f}, Test: {test_acc:.4f}\")\n",
        "\n",
        "print(f\"\\nBest Validation Accuracy: {best_val_acc:.4f}\")\n",
        "print(f\"Test Accuracy at Best Val: {test_acc_at_best_val:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import product\n",
        "\n",
        "# Define the search space for hyperparameters\n",
        "param_grid = {\n",
        "    'lr': [0.01, 0.001, 0.0001],\n",
        "    'hidden_dim': [64],\n",
        "    'weight_decay': [1e-5, 1e-4, 1e-3],\n",
        "    'dropout_prob': [0.2, 0.3, 0.5]\n",
        "}\n",
        "\n",
        "# Expand the grid into combinations\n",
        "param_combinations = list(product(*param_grid.values()))\n",
        "best_val_acc = 0\n",
        "best_params = None\n",
        "best_test_acc = 0\n",
        "\n",
        "# Function to train and evaluate the model\n",
        "def train_and_evaluate(lr, hidden_dim, weight_decay, dropout_prob):\n",
        "    model = PNAModelWithAttention(\n",
        "        in_channels=dataset.num_node_features,\n",
        "        hidden_channels=hidden_dim,\n",
        "        out_channels=dataset.num_classes,\n",
        "        aggregators=aggregators,\n",
        "        scalers=scalers,\n",
        "        deg=deg,\n",
        "        node_embeddings=node_embeddings\n",
        "    ).to(device)\n",
        "\n",
        "    # Add dropout to the model\n",
        "    model.dropout = nn.Dropout(p=dropout_prob)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Training and validation loop\n",
        "    best_val = 0\n",
        "    test_acc_at_best_val = 0\n",
        "    for epoch in range(1, 201):\n",
        "        # Training\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data.x, data.edge_index)\n",
        "        loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Validation and test\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            out = model(data.x, data.edge_index)\n",
        "            pred = out.argmax(dim=1)\n",
        "            train_acc = pred[data.train_mask].eq(data.y[data.train_mask]).sum().item() / data.train_mask.sum().item()\n",
        "            val_acc = pred[data.val_mask].eq(data.y[data.val_mask]).sum().item() / data.val_mask.sum().item()\n",
        "            test_acc = pred[data.test_mask].eq(data.y[data.test_mask]).sum().item() / data.test_mask.sum().item()\n",
        "\n",
        "        if val_acc > best_val:\n",
        "            best_val = val_acc\n",
        "            test_acc_at_best_val = test_acc\n",
        "\n",
        "    return best_val, test_acc_at_best_val\n",
        "\n",
        "# Run the grid search\n",
        "for params in param_combinations:\n",
        "    lr, hidden_dim, weight_decay, dropout_prob = params\n",
        "    print(f\"Testing params: lr={lr}, hidden_dim={hidden_dim}, weight_decay={weight_decay}, dropout_prob={dropout_prob}\")\n",
        "\n",
        "    val_acc, test_acc = train_and_evaluate(lr, hidden_dim, weight_decay, dropout_prob)\n",
        "\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        best_test_acc = test_acc\n",
        "        best_params = params\n",
        "\n",
        "    print(f\"Validation Accuracy: {val_acc:.4f}, Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "# Output the best parameters and performance\n",
        "print(\"\\nBest Hyperparameters:\")\n",
        "print(f\"Learning Rate: {best_params[0]}, Hidden Dimension: {best_params[1]}, Weight Decay: {best_params[2]}, Dropout Probability: {best_params[3]}\")\n",
        "print(f\"Best Validation Accuracy: {best_val_acc:.4f}\")\n",
        "print(f\"Test Accuracy at Best Validation: {best_test_acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1iDzkNyU8M7",
        "outputId": "5693097c-7b59-4046-c027-a59d1feec057"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing params: lr=0.01, hidden_dim=64, weight_decay=1e-05, dropout_prob=0.2\n",
            "Validation Accuracy: 0.6800, Test Accuracy: 0.6610\n",
            "Testing params: lr=0.01, hidden_dim=64, weight_decay=1e-05, dropout_prob=0.3\n",
            "Validation Accuracy: 0.5680, Test Accuracy: 0.5860\n",
            "Testing params: lr=0.01, hidden_dim=64, weight_decay=1e-05, dropout_prob=0.5\n",
            "Validation Accuracy: 0.6180, Test Accuracy: 0.6200\n",
            "Testing params: lr=0.01, hidden_dim=64, weight_decay=0.0001, dropout_prob=0.2\n",
            "Validation Accuracy: 0.6620, Test Accuracy: 0.6910\n",
            "Testing params: lr=0.01, hidden_dim=64, weight_decay=0.0001, dropout_prob=0.3\n",
            "Validation Accuracy: 0.6940, Test Accuracy: 0.7070\n",
            "Testing params: lr=0.01, hidden_dim=64, weight_decay=0.0001, dropout_prob=0.5\n",
            "Validation Accuracy: 0.7100, Test Accuracy: 0.7230\n",
            "Testing params: lr=0.01, hidden_dim=64, weight_decay=0.001, dropout_prob=0.2\n",
            "Validation Accuracy: 0.6700, Test Accuracy: 0.6530\n",
            "Testing params: lr=0.01, hidden_dim=64, weight_decay=0.001, dropout_prob=0.3\n",
            "Validation Accuracy: 0.7000, Test Accuracy: 0.6980\n",
            "Testing params: lr=0.01, hidden_dim=64, weight_decay=0.001, dropout_prob=0.5\n",
            "Validation Accuracy: 0.6800, Test Accuracy: 0.6800\n",
            "Testing params: lr=0.001, hidden_dim=64, weight_decay=1e-05, dropout_prob=0.2\n",
            "Validation Accuracy: 0.6740, Test Accuracy: 0.6670\n",
            "Testing params: lr=0.001, hidden_dim=64, weight_decay=1e-05, dropout_prob=0.3\n",
            "Validation Accuracy: 0.6400, Test Accuracy: 0.6360\n",
            "Testing params: lr=0.001, hidden_dim=64, weight_decay=1e-05, dropout_prob=0.5\n",
            "Validation Accuracy: 0.6460, Test Accuracy: 0.6270\n",
            "Testing params: lr=0.001, hidden_dim=64, weight_decay=0.0001, dropout_prob=0.2\n",
            "Validation Accuracy: 0.6940, Test Accuracy: 0.7130\n",
            "Testing params: lr=0.001, hidden_dim=64, weight_decay=0.0001, dropout_prob=0.3\n",
            "Validation Accuracy: 0.6700, Test Accuracy: 0.6690\n",
            "Testing params: lr=0.001, hidden_dim=64, weight_decay=0.0001, dropout_prob=0.5\n",
            "Validation Accuracy: 0.6640, Test Accuracy: 0.6610\n",
            "Testing params: lr=0.001, hidden_dim=64, weight_decay=0.001, dropout_prob=0.2\n",
            "Validation Accuracy: 0.6840, Test Accuracy: 0.6840\n",
            "Testing params: lr=0.001, hidden_dim=64, weight_decay=0.001, dropout_prob=0.3\n",
            "Validation Accuracy: 0.6680, Test Accuracy: 0.6580\n",
            "Testing params: lr=0.001, hidden_dim=64, weight_decay=0.001, dropout_prob=0.5\n",
            "Validation Accuracy: 0.7020, Test Accuracy: 0.6810\n",
            "Testing params: lr=0.0001, hidden_dim=64, weight_decay=1e-05, dropout_prob=0.2\n",
            "Validation Accuracy: 0.7200, Test Accuracy: 0.7070\n",
            "Testing params: lr=0.0001, hidden_dim=64, weight_decay=1e-05, dropout_prob=0.3\n",
            "Validation Accuracy: 0.7180, Test Accuracy: 0.7010\n",
            "Testing params: lr=0.0001, hidden_dim=64, weight_decay=1e-05, dropout_prob=0.5\n",
            "Validation Accuracy: 0.6280, Test Accuracy: 0.6100\n",
            "Testing params: lr=0.0001, hidden_dim=64, weight_decay=0.0001, dropout_prob=0.2\n",
            "Validation Accuracy: 0.5520, Test Accuracy: 0.5270\n",
            "Testing params: lr=0.0001, hidden_dim=64, weight_decay=0.0001, dropout_prob=0.3\n",
            "Validation Accuracy: 0.6660, Test Accuracy: 0.6370\n",
            "Testing params: lr=0.0001, hidden_dim=64, weight_decay=0.0001, dropout_prob=0.5\n",
            "Validation Accuracy: 0.6880, Test Accuracy: 0.6720\n",
            "Testing params: lr=0.0001, hidden_dim=64, weight_decay=0.001, dropout_prob=0.2\n",
            "Validation Accuracy: 0.6160, Test Accuracy: 0.6410\n",
            "Testing params: lr=0.0001, hidden_dim=64, weight_decay=0.001, dropout_prob=0.3\n",
            "Validation Accuracy: 0.5960, Test Accuracy: 0.5820\n",
            "Testing params: lr=0.0001, hidden_dim=64, weight_decay=0.001, dropout_prob=0.5\n",
            "Validation Accuracy: 0.6460, Test Accuracy: 0.6390\n",
            "\n",
            "Best Hyperparameters:\n",
            "Learning Rate: 0.0001, Hidden Dimension: 64, Weight Decay: 1e-05, Dropout Probability: 0.2\n",
            "Best Validation Accuracy: 0.7200\n",
            "Test Accuracy at Best Validation: 0.7070\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}